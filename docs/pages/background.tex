\chapter{图像有损压缩技术的背景}

\section{图像压缩概述}

原始的数字图像数据可以占用相当大的存储空间，在计算机的存储、传输、处理等环节将产生很大的计算处理负担，因此图像数据的压缩就显得非常重要了。

例如一张尺寸为3840\times2180的原始图像，如果每个像素使用32bit（RGBA）来表示，那么存储这一张图像需要占用的空间为 3840\times2180\times4=33484800Byte≈31.9MB。相应的，如果拍摄1 分钟 30 帧(fps)的4k视频，那么需要的存储空间将会达到3840\times2180\times4\times30\times60 ≈ 56.1GB。由此看来，对于图像视频，尤其是视频的数据压缩就显得尤为重要了。

图像数据是用来表示图像信息的，不同的方法表示相同的图像信息会使用不同的数据量，不同的方法中，必然会有一些会产生不必要的重复或者无用信息，重复的信息属于不相干信息，无用的信息属于冗余信息。图像压缩编码的主要目的，就是通过删除冗余的或者是不相干的信息，以尽可能小的存储、尽可能低的码率来传输数字图像数据。

信息时代带来了“信息爆炸”，使数据量大增，因此，无论传输或存储都需要对数据进行有效的压缩。在遥感技术中，各种航天探测器采用压缩编码技术，将获取的巨大信息送回地面。


\section{图像压缩的基本原理}

图像数据之所以能被压缩，就是因为图像数据中存在着冗余部分。
图像数据的冗余主要表现为4种：
\begin{itemize}
    \item \textbf{空间冗余}。一幅图像表面上各像素点之间往往存在着空间连贯性，相邻像素之前也存在相关性，由此产生的空间冗余；
    \item \textbf{时间冗余}。视频的相邻帧往往包含相同的背景和移动物体，相邻帧之间存在相关性，由此产生的时间冗余；
    \item \textbf{频谱冗余}。不同彩色平面或频谱带之间存在相关，由此产生的频谱冗余；
    \item \textbf{视觉冗余}。人类的视觉系统由于受生理特性的限制，对于图像场的注意是非均匀的，人对细微的颜色差异感觉不明显。
\end{itemize}

\section{图像压缩的分类}
根据压缩后的图像是否能完全恢复，可以将图像压缩技术分为无损压缩和有损压缩两类。
\subsection{图像的无损压缩}

利用无损压缩方法消除或减少的各种形式的冗余可以重新插入到数据中，因此，无损压缩是可逆过程，也称无失真压缩。

为了消除或减少数据中的冗余度，常常要用信源的统计特性或建立信源的统计模型，因此许多实用的无损压缩技术均可归结为统计编码方法。

统计编码方法中常用的有 Huffman 编码、算术编码、RLE(Run Length Encoding)编码等。 此外统计编码技术在各种有损压缩 方法中也有广泛的应用。

\subsection{图像的有损压缩}

有损压缩法压缩了熵，信息量会减少，而损失的信息量不能再恢复，因此有损压缩是不可逆过程。 有损压缩主要有两大类:特征 提取和量化方法。 特征提取的编码方法如模型基编码、分形编码等。 量化是有损压缩最基本的形式，其优点是可以得到比无损压缩 高得多的压缩比。 有损压缩只能用于允许一定程度失真的情况，比如对图像、声音、视频等数据的压缩。
无损压缩和有损压缩结合形成了混合编码技术，它融合了各种不同的压缩编码技术，很多国际标准都是采用混合编码技术，如 JPEG，MPEG 等标准。 利用混合编码对自然景物的灰度图像进行压缩一般可压缩几倍到十几倍，而对于自然景物的彩色图像压缩比 将达到几十甚至上百倍。

\section{图像压缩的发展现状}

早在1948年，当电视信号数字化之后，图像压缩的研究就逐渐展开了，1952年，哈夫曼提出了“最小冗余代码构造方法”，1968年，Elisa发展了香农和费诺的编码方法，，1976年，算术编码的方法被提出，1982年算术编码预测模型结合。20世纪80年代，由于神经网络的应用逐步广泛，1987年，就提出了人工神经网络预测编码，1994年，JPEG标准正式成为国际标准，在7年后的2001年，JPEG2000正式确立。近年来，随着深度学习技术的不断发展深入，越来越多的深度学习技术被应用在了图像编码算法上，例如2016年Balle等人提出的卷积神经网络CNN图像编码框架，2017年Rippel和Bourde发表了基于生成对抗网络GAN的图像编码器，同年，Google的研究人员提出了循环神经网络RNN的图像编码器。
